{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# scaling and train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# creating a model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# evaluation on test data\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(r\"Data\\train_data_binned.csv\")\n",
    "test_data = pd.read_csv(r\"Data\\test_data_binned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 18</th>\n",
       "      <th>Feature 19</th>\n",
       "      <th>Feature 20</th>\n",
       "      <th>Feature 21</th>\n",
       "      <th>Feature 22</th>\n",
       "      <th>Feature 23</th>\n",
       "      <th>Feature  24</th>\n",
       "      <th>Feature 25</th>\n",
       "      <th>Feature 26</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>132523</td>\n",
       "      <td>132523</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.1</td>\n",
       "      <td>59.0</td>\n",
       "      <td>6.04</td>\n",
       "      <td>5.99</td>\n",
       "      <td>3.61</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>70210</td>\n",
       "      <td>70210</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.1</td>\n",
       "      <td>54.0</td>\n",
       "      <td>5.31</td>\n",
       "      <td>5.28</td>\n",
       "      <td>3.28</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>93051</td>\n",
       "      <td>93051</td>\n",
       "      <td>1.01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61.6</td>\n",
       "      <td>62.0</td>\n",
       "      <td>6.40</td>\n",
       "      <td>6.35</td>\n",
       "      <td>3.92</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>67325</td>\n",
       "      <td>67325</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>62.9</td>\n",
       "      <td>58.0</td>\n",
       "      <td>4.26</td>\n",
       "      <td>4.30</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>189522</td>\n",
       "      <td>189522</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>62.4</td>\n",
       "      <td>58.0</td>\n",
       "      <td>3.96</td>\n",
       "      <td>3.98</td>\n",
       "      <td>2.47</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58067</th>\n",
       "      <td>58067</td>\n",
       "      <td>51474</td>\n",
       "      <td>51474</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>61.8</td>\n",
       "      <td>56.0</td>\n",
       "      <td>6.34</td>\n",
       "      <td>6.48</td>\n",
       "      <td>3.96</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58068</th>\n",
       "      <td>58068</td>\n",
       "      <td>50296</td>\n",
       "      <td>50296</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.1</td>\n",
       "      <td>57.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>5.77</td>\n",
       "      <td>3.58</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58069</th>\n",
       "      <td>58069</td>\n",
       "      <td>95077</td>\n",
       "      <td>95077</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62.2</td>\n",
       "      <td>58.0</td>\n",
       "      <td>6.59</td>\n",
       "      <td>6.54</td>\n",
       "      <td>4.08</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58070</th>\n",
       "      <td>58070</td>\n",
       "      <td>71500</td>\n",
       "      <td>71500</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>6.42</td>\n",
       "      <td>6.35</td>\n",
       "      <td>3.71</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58071</th>\n",
       "      <td>58071</td>\n",
       "      <td>114675</td>\n",
       "      <td>114675</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60.6</td>\n",
       "      <td>56.0</td>\n",
       "      <td>5.74</td>\n",
       "      <td>5.77</td>\n",
       "      <td>3.49</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>58072 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0      id  Feature 1  Feature 2  Feature 3   \n",
       "0                 0      132523  132523       0.80          0          0  \\\n",
       "1                 1       70210   70210       0.56          0          0   \n",
       "2                 2       93051   93051       1.01          0          0   \n",
       "3                 3       67325   67325       0.30          0          0   \n",
       "4                 4      189522  189522       0.23          0          0   \n",
       "...             ...         ...     ...        ...        ...        ...   \n",
       "58067         58067       51474   51474       1.00          0          0   \n",
       "58068         58068       50296   50296       0.73          0          0   \n",
       "58069         58069       95077   95077       1.10          0          0   \n",
       "58070         58070       71500   71500       0.91          0          0   \n",
       "58071         58071      114675  114675       0.71          0          0   \n",
       "\n",
       "       Feature 4  Feature 5  Feature 6  Feature 7  ...  Feature 18   \n",
       "0              0          1          0          0  ...           0  \\\n",
       "1              1          0          0          0  ...           0   \n",
       "2              0          1          0          0  ...           0   \n",
       "3              0          0          1          0  ...           0   \n",
       "4              0          1          0          0  ...           0   \n",
       "...          ...        ...        ...        ...  ...         ...   \n",
       "58067          1          0          0          1  ...           0   \n",
       "58068          1          0          0          0  ...           0   \n",
       "58069          0          1          0          0  ...           0   \n",
       "58070          0          1          0          0  ...           1   \n",
       "58071          1          0          0          0  ...           0   \n",
       "\n",
       "       Feature 19  Feature 20  Feature 21  Feature 22  Feature 23   \n",
       "0               0           0           0        60.1        59.0  \\\n",
       "1               0           0           0        62.1        54.0   \n",
       "2               0           0           0        61.6        62.0   \n",
       "3               0           1           0        62.9        58.0   \n",
       "4               0           0           1        62.4        58.0   \n",
       "...           ...         ...         ...         ...         ...   \n",
       "58067           0           0           0        61.8        56.0   \n",
       "58068           0           0           0        62.1        57.0   \n",
       "58069           0           0           0        62.2        58.0   \n",
       "58070           0           0           0        58.0        60.0   \n",
       "58071           0           0           0        60.6        56.0   \n",
       "\n",
       "       Feature  24  Feature 25  Feature 26  bin  \n",
       "0             6.04        5.99        3.61    2  \n",
       "1             5.31        5.28        3.28    2  \n",
       "2             6.40        6.35        3.92    3  \n",
       "3             4.26        4.30        2.69    1  \n",
       "4             3.96        3.98        2.47    1  \n",
       "...            ...         ...         ...  ...  \n",
       "58067         6.34        6.48        3.96    2  \n",
       "58068         5.74        5.77        3.58    2  \n",
       "58069         6.59        6.54        4.08    3  \n",
       "58070         6.42        6.35        3.71    3  \n",
       "58071         5.74        5.77        3.49    2  \n",
       "\n",
       "[58072 rows x 30 columns]"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Feature 1',\n",
       " 'Feature 2',\n",
       " 'Feature 3',\n",
       " 'Feature 4',\n",
       " 'Feature 5',\n",
       " 'Feature 6',\n",
       " 'Feature 7',\n",
       " 'Feature 8',\n",
       " 'Feature 9',\n",
       " 'Feature 10',\n",
       " 'Feature 11',\n",
       " 'Feature 12',\n",
       " 'Feature 13',\n",
       " 'Feature 14',\n",
       " 'Feature 15',\n",
       " 'Feature 16',\n",
       " 'Feature 17',\n",
       " 'Feature 18',\n",
       " 'Feature 19',\n",
       " 'Feature 20',\n",
       " 'Feature 21',\n",
       " 'Feature 22',\n",
       " 'Feature 23',\n",
       " 'Feature  24',\n",
       " 'Feature 25',\n",
       " 'Feature 26']"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = list(train_data.columns)\n",
    "col.remove('Unnamed: 0')\n",
    "col.remove('Unnamed: 0.1')\n",
    "col.remove('id')\n",
    "col.remove('price')\n",
    "col.remove('bin')\n",
    "#col.remove('Feature 2')\n",
    "#col.remove('Feature 3')\n",
    "#col.remove('Feature 4')\n",
    "#col.remove('Feature 5')\n",
    "#col.remove('Feature 6')\n",
    "#col.remove('Feature 11')\n",
    "#col.remove('Feature 15')\n",
    "#col.remove('Feature 18')\n",
    "#col.remove('Feature 19')\n",
    "#col.remove('Feature 20')\n",
    "#col.remove('Feature 21')\n",
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['train-test'] = \"train\"\n",
    "test_data['train-test'] = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([train_data,test_data]).fillna('TBC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "combined_df[\"Feature 1\"] = scaler.fit_transform(np.array(combined_df[\"Feature 1\"]).reshape(-1,1))\n",
    "combined_df[\"Feature 22\"] = scaler.fit_transform(np.array(combined_df[\"Feature 22\"]).reshape(-1,1))\n",
    "combined_df[\"Feature 23\"] = scaler.fit_transform(np.array(combined_df[\"Feature 23\"]).reshape(-1,1))\n",
    "combined_df[\"Feature  24\"] = scaler.fit_transform(np.array(combined_df[\"Feature  24\"]).reshape(-1,1))\n",
    "combined_df[\"Feature 25\"] = scaler.fit_transform(np.array(combined_df[\"Feature 25\"]).reshape(-1,1))\n",
    "combined_df[\"Feature 26\"] = scaler.fit_transform(np.array(combined_df[\"Feature 26\"]).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_group = combined_df.groupby(['train-test'])\n",
    "train_data = df_group.get_group('train')\n",
    "test_data = df_group.get_group('test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.drop('train-test',axis=1)\n",
    "test_data = test_data.drop('train-test',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.drop('price',axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>Feature 1</th>\n",
       "      <th>Feature 2</th>\n",
       "      <th>Feature 3</th>\n",
       "      <th>Feature 4</th>\n",
       "      <th>Feature 5</th>\n",
       "      <th>Feature 6</th>\n",
       "      <th>Feature 7</th>\n",
       "      <th>...</th>\n",
       "      <th>Feature 19</th>\n",
       "      <th>Feature 20</th>\n",
       "      <th>Feature 21</th>\n",
       "      <th>Feature 22</th>\n",
       "      <th>Feature 23</th>\n",
       "      <th>Feature  24</th>\n",
       "      <th>Feature 25</th>\n",
       "      <th>Feature 26</th>\n",
       "      <th>price</th>\n",
       "      <th>bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>143728</td>\n",
       "      <td>143728</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.507692</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.534715</td>\n",
       "      <td>0.519481</td>\n",
       "      <td>0.102556</td>\n",
       "      <td>1656.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>52657</td>\n",
       "      <td>52657</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.506736</td>\n",
       "      <td>0.501499</td>\n",
       "      <td>0.101597</td>\n",
       "      <td>1063.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>124407</td>\n",
       "      <td>124407</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364103</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.869430</td>\n",
       "      <td>0.828172</td>\n",
       "      <td>0.157827</td>\n",
       "      <td>18508.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>45535</td>\n",
       "      <td>45535</td>\n",
       "      <td>0.039394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.482051</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.456995</td>\n",
       "      <td>0.446553</td>\n",
       "      <td>0.087220</td>\n",
       "      <td>723.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>178894</td>\n",
       "      <td>178894</td>\n",
       "      <td>0.212121</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.589744</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.625907</td>\n",
       "      <td>0.607393</td>\n",
       "      <td>0.123323</td>\n",
       "      <td>3187.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135496</th>\n",
       "      <td>135496</td>\n",
       "      <td>34345</td>\n",
       "      <td>34345</td>\n",
       "      <td>0.151515</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.574359</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.585492</td>\n",
       "      <td>0.560440</td>\n",
       "      <td>0.113738</td>\n",
       "      <td>2380.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135497</th>\n",
       "      <td>135497</td>\n",
       "      <td>9899</td>\n",
       "      <td>9899</td>\n",
       "      <td>0.039394</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.459067</td>\n",
       "      <td>0.439560</td>\n",
       "      <td>0.088498</td>\n",
       "      <td>693.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135498</th>\n",
       "      <td>135498</td>\n",
       "      <td>142454</td>\n",
       "      <td>142454</td>\n",
       "      <td>0.554545</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.389744</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.868394</td>\n",
       "      <td>0.829171</td>\n",
       "      <td>0.158786</td>\n",
       "      <td>16068.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135499</th>\n",
       "      <td>135499</td>\n",
       "      <td>129168</td>\n",
       "      <td>129168</td>\n",
       "      <td>0.160606</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.569231</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.587565</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.115335</td>\n",
       "      <td>2964.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135500</th>\n",
       "      <td>135500</td>\n",
       "      <td>10470</td>\n",
       "      <td>10470</td>\n",
       "      <td>0.460606</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.466667</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.794819</td>\n",
       "      <td>0.771229</td>\n",
       "      <td>0.150479</td>\n",
       "      <td>15847.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>135501 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0.1  Unnamed: 0      id  Feature 1  Feature 2  Feature 3   \n",
       "0                  0      143728  143728   0.100000          0          0  \\\n",
       "1                  1       52657   52657   0.090909          0          1   \n",
       "2                  2      124407  124407   0.554545          0          0   \n",
       "3                  3       45535   45535   0.039394          0          0   \n",
       "4                  4      178894  178894   0.212121          0          1   \n",
       "...              ...         ...     ...        ...        ...        ...   \n",
       "135496        135496       34345   34345   0.151515          0          1   \n",
       "135497        135497        9899    9899   0.039394          0          0   \n",
       "135498        135498      142454  142454   0.554545          0          0   \n",
       "135499        135499      129168  129168   0.160606          0          1   \n",
       "135500        135500       10470   10470   0.460606          0          0   \n",
       "\n",
       "        Feature 4  Feature 5  Feature 6  Feature 7  ...  Feature 19   \n",
       "0               1          0          0          0  ...           1  \\\n",
       "1               0          0          0          0  ...           0   \n",
       "2               1          0          0          0  ...           0   \n",
       "3               1          0          0          0  ...           1   \n",
       "4               0          0          0          0  ...           1   \n",
       "...           ...        ...        ...        ...  ...         ...   \n",
       "135496          0          0          0          1  ...           0   \n",
       "135497          1          0          0          0  ...           0   \n",
       "135498          0          1          0          0  ...           1   \n",
       "135499          0          0          0          0  ...           1   \n",
       "135500          1          0          0          0  ...           0   \n",
       "\n",
       "        Feature 20  Feature 21  Feature 22  Feature 23  Feature  24   \n",
       "0                0           0    0.507692    0.233333     0.534715  \\\n",
       "1                0           0    0.600000    0.233333     0.506736   \n",
       "2                0           0    0.364103    0.366667     0.869430   \n",
       "3                0           0    0.482051    0.200000     0.456995   \n",
       "4                0           0    0.589744    0.333333     0.625907   \n",
       "...            ...         ...         ...         ...          ...   \n",
       "135496           0           0    0.574359    0.266667     0.585492   \n",
       "135497           0           0    0.538462    0.266667     0.459067   \n",
       "135498           0           0    0.389744    0.333333     0.868394   \n",
       "135499           0           0    0.569231    0.333333     0.587565   \n",
       "135500           0           0    0.466667    0.266667     0.794819   \n",
       "\n",
       "        Feature 25  Feature 26    price  bin  \n",
       "0         0.519481    0.102556   1656.0    2  \n",
       "1         0.501499    0.101597   1063.0    1  \n",
       "2         0.828172    0.157827  18508.0    3  \n",
       "3         0.446553    0.087220    723.0    1  \n",
       "4         0.607393    0.123323   3187.0    2  \n",
       "...            ...         ...      ...  ...  \n",
       "135496    0.560440    0.113738   2380.0    2  \n",
       "135497    0.439560    0.088498    693.0    1  \n",
       "135498    0.829171    0.158786  16068.0    3  \n",
       "135499    0.571429    0.115335   2964.0    2  \n",
       "135500    0.771229    0.150479  15847.0    3  \n",
       "\n",
       "[135501 rows x 31 columns]"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# input layer\n",
    "model.add(Dense(26,activation='relu'))\n",
    "\n",
    "# hidden layers\n",
    "model.add(Dense(64,activation='relu'))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(16,activation='relu'))\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(4,activation='relu'))\n",
    "\n",
    "\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(1,activation='relu'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bin_1 = train_data.loc[train_data['bin'] == 1]\n",
    "train_data_bin_1_input = train_data_bin_1[col]\n",
    "train_data_bin_1_target = train_data_bin_1['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bin_1_target_min = train_data_bin_1_target.min()\n",
    "train_data_bin_1_target_max = train_data_bin_1_target.max()\n",
    "#print(train_data_bin_1_target_max)\n",
    "#train_data_bin_1_target_min = 0\n",
    "# normalize y\n",
    "train_data_bin_1_target_norm = (train_data_bin_1_target - train_data_bin_1_target_min) / (train_data_bin_1_target_max - train_data_bin_1_target_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test,y_train,y_test = train_test_split(train_data_bin_1_input,train_data_bin_1_target, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normal(data):\n",
    "    data_min = data.min()\n",
    "    data_max = data.max()\n",
    "    data_norm = (data - data_min) / (data_max - data_min)\n",
    "    return(data_norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "285/285 [==============================] - 2s 2ms/step - loss: 0.0840 - val_loss: 0.0414\n",
      "Epoch 2/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0349 - val_loss: 0.0219\n",
      "Epoch 3/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0146 - val_loss: 0.0123\n",
      "Epoch 4/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0121 - val_loss: 0.0122\n",
      "Epoch 5/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0115 - val_loss: 0.0114\n",
      "Epoch 6/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 7/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0111 - val_loss: 0.0119\n",
      "Epoch 8/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0108\n",
      "Epoch 9/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0110 - val_loss: 0.0124\n",
      "Epoch 10/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0109 - val_loss: 0.0108\n",
      "Epoch 11/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0107 - val_loss: 0.0105\n",
      "Epoch 12/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0107\n",
      "Epoch 13/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0105 - val_loss: 0.0108\n",
      "Epoch 14/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0103\n",
      "Epoch 15/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0106 - val_loss: 0.0128\n",
      "Epoch 16/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0104 - val_loss: 0.0106\n",
      "Epoch 17/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0105\n",
      "Epoch 18/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 19/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 20/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0102\n",
      "Epoch 21/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0104\n",
      "Epoch 22/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0103 - val_loss: 0.0101\n",
      "Epoch 23/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 24/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 25/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0101\n",
      "Epoch 26/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0101\n",
      "Epoch 27/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0103\n",
      "Epoch 28/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0102 - val_loss: 0.0100\n",
      "Epoch 29/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0100\n",
      "Epoch 30/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 31/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 32/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0100\n",
      "Epoch 33/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0102\n",
      "Epoch 34/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0101 - val_loss: 0.0099\n",
      "Epoch 35/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0101\n",
      "Epoch 36/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 37/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 38/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 39/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 40/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0098\n",
      "Epoch 41/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0102\n",
      "Epoch 42/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 43/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0100 - val_loss: 0.0099\n",
      "Epoch 44/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 45/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 46/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 47/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0100\n",
      "Epoch 48/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 49/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0099 - val_loss: 0.0099\n",
      "Epoch 50/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 51/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 52/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 53/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 54/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 55/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0096\n",
      "Epoch 56/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 57/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 58/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 59/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0100\n",
      "Epoch 60/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0101\n",
      "Epoch 61/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 62/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 63/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0097\n",
      "Epoch 64/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 65/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 66/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 67/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 68/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0096\n",
      "Epoch 69/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 70/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 71/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 72/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0098\n",
      "Epoch 73/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 74/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0098 - val_loss: 0.0099\n",
      "Epoch 75/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 76/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 77/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0098\n",
      "Epoch 78/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 79/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0110\n",
      "Epoch 80/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 81/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 82/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 83/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0099\n",
      "Epoch 84/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0099\n",
      "Epoch 85/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0100\n",
      "Epoch 86/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 87/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0103\n",
      "Epoch 88/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0104\n",
      "Epoch 89/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 90/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 91/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 92/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 93/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 94/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0097 - val_loss: 0.0097\n",
      "Epoch 95/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 96/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 97/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0102\n",
      "Epoch 98/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 99/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0098\n",
      "Epoch 100/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 101/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 102/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 103/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 104/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0096\n",
      "Epoch 105/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 106/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 107/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 108/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 109/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 110/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 111/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0096 - val_loss: 0.0097\n",
      "Epoch 112/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 113/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 114/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 115/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 116/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 117/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0100\n",
      "Epoch 118/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 119/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 120/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 121/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0104\n",
      "Epoch 122/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 123/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 124/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0099\n",
      "Epoch 125/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 126/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 127/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0097\n",
      "Epoch 128/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0098\n",
      "Epoch 129/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 130/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 131/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 132/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 133/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 134/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 135/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 136/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 137/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 138/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 139/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 140/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 141/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0095 - val_loss: 0.0096\n",
      "Epoch 142/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 143/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 144/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0101\n",
      "Epoch 145/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0099\n",
      "Epoch 146/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 147/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 148/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0098\n",
      "Epoch 149/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 150/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 151/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0100\n",
      "Epoch 152/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 153/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 154/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 155/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 156/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 157/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 158/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 159/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0107\n",
      "Epoch 160/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0096\n",
      "Epoch 161/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 162/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 163/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 164/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0094 - val_loss: 0.0097\n",
      "Epoch 165/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 166/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0100\n",
      "Epoch 167/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 168/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 169/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0098\n",
      "Epoch 170/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 171/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 172/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 173/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 174/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 175/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 176/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 177/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 178/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 179/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 180/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 181/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 182/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 183/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0105\n",
      "Epoch 184/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 185/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0095\n",
      "Epoch 186/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 187/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 188/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 189/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 190/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 191/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 192/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 193/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 194/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 195/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0097\n",
      "Epoch 196/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 197/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 198/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0099\n",
      "Epoch 199/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 200/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 201/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 202/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 203/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 204/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0098\n",
      "Epoch 205/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 206/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 207/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 208/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 209/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 210/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 211/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 212/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 213/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 214/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0099\n",
      "Epoch 215/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 216/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 217/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0093 - val_loss: 0.0096\n",
      "Epoch 218/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 219/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 220/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0102\n",
      "Epoch 221/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0100\n",
      "Epoch 222/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 223/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 224/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0102\n",
      "Epoch 225/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 226/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 227/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 228/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 229/500\n",
      "285/285 [==============================] - 1s 2ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 230/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0105\n",
      "Epoch 231/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 232/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 233/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 234/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0097\n",
      "Epoch 235/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0096\n",
      "Epoch 236/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 237/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 238/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 239/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 240/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 241/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 242/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 243/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 244/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 245/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 246/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 247/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 248/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 249/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 250/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0092 - val_loss: 0.0095\n",
      "Epoch 251/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 252/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 253/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 254/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0098\n",
      "Epoch 255/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0099\n",
      "Epoch 256/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 257/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 258/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 259/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 260/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 261/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 262/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 263/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0099\n",
      "Epoch 264/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 265/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0097\n",
      "Epoch 266/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 267/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0102\n",
      "Epoch 268/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 269/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 270/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0096\n",
      "Epoch 271/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 272/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 273/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 274/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 275/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 276/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 277/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 278/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 279/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0091 - val_loss: 0.0095\n",
      "Epoch 280/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 281/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 282/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 283/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 284/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 285/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 286/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 287/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 288/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 289/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 290/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 291/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0101\n",
      "Epoch 292/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0100\n",
      "Epoch 293/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 294/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 295/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0095\n",
      "Epoch 296/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 297/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 298/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 299/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 300/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 301/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 302/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 303/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 304/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 305/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 306/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 307/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 308/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 309/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 310/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 311/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 312/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 313/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 314/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 315/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 316/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0096\n",
      "Epoch 317/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 318/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 319/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 320/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 321/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0097\n",
      "Epoch 322/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 323/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 324/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 325/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 326/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 327/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0090 - val_loss: 0.0098\n",
      "Epoch 328/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 329/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 330/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 331/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0097\n",
      "Epoch 332/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 333/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 334/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 335/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 336/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 337/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 338/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 339/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 340/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 341/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 342/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 343/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 344/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 345/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0098\n",
      "Epoch 346/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 347/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 348/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0100\n",
      "Epoch 349/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 350/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 351/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 352/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0095\n",
      "Epoch 353/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 354/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0089 - val_loss: 0.0096\n",
      "Epoch 355/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0099\n",
      "Epoch 356/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0098\n",
      "Epoch 357/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 358/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 359/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 360/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 361/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 362/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 363/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 364/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 365/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 366/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 367/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 368/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 369/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 370/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0099\n",
      "Epoch 371/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 372/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 373/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 374/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 375/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0097\n",
      "Epoch 376/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 377/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 378/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 379/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 380/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 381/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 382/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 383/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 384/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 385/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 386/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 387/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 388/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0094\n",
      "Epoch 389/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 390/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 391/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 392/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 393/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 394/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 395/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0096\n",
      "Epoch 396/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 397/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 398/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 399/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 400/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 401/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0101\n",
      "Epoch 402/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0101\n",
      "Epoch 403/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 404/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 405/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 406/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 407/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 408/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 409/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0088 - val_loss: 0.0095\n",
      "Epoch 410/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 411/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 412/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 413/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 414/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 415/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 416/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 417/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 418/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 419/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 420/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 421/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 422/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 423/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 424/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 425/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 426/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 427/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0087 - val_loss: 0.0097\n",
      "Epoch 428/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 429/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 430/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0098\n",
      "Epoch 431/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 432/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 433/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 434/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 435/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 436/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 437/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 438/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 439/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 440/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 441/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0096\n",
      "Epoch 442/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 443/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0099\n",
      "Epoch 444/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0095\n",
      "Epoch 445/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 446/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 447/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 448/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 449/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 450/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 451/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 452/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 453/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0101\n",
      "Epoch 454/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 455/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 456/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 457/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0087 - val_loss: 0.0094\n",
      "Epoch 458/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 459/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 460/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 461/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 462/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 463/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0098\n",
      "Epoch 464/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 465/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 466/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 467/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 468/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 469/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 470/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 471/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 472/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 473/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 474/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 475/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0097\n",
      "Epoch 476/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 477/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 478/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0102\n",
      "Epoch 479/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 480/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 481/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 482/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 483/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0098\n",
      "Epoch 484/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0096\n",
      "Epoch 485/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 486/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 487/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 488/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 489/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 490/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0094\n",
      "Epoch 491/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 492/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0097\n",
      "Epoch 493/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 494/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 495/500\n",
      "285/285 [==============================] - 0s 2ms/step - loss: 0.0085 - val_loss: 0.0094\n",
      "Epoch 496/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 497/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0086 - val_loss: 0.0095\n",
      "Epoch 498/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0096\n",
      "Epoch 499/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0095\n",
      "Epoch 500/500\n",
      "285/285 [==============================] - 0s 1ms/step - loss: 0.0085 - val_loss: 0.0093\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c1c0c0a940>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train.values,\n",
    "          validation_data=(X_test,y_test.values),\n",
    "          batch_size=128,epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "285/285 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.3656345 ],\n",
       "       [0.35234383],\n",
       "       [0.4615171 ],\n",
       "       ...,\n",
       "       [0.42904422],\n",
       "       [0.15179583],\n",
       "       [0.613266  ]], dtype=float32)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_denorm = y_pred * (train_data_bin_1_target_max - train_data_bin_1_target_min) + (train_data_bin_1_target_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[663.8463 ],\n",
       "       [651.5657 ],\n",
       "       [752.4418 ],\n",
       "       ...,\n",
       "       [722.4369 ],\n",
       "       [466.25934],\n",
       "       [892.6578 ]], dtype=float32)"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_denorm = y_test * (train_data_bin_1_target_max - train_data_bin_1_target_min) + (train_data_bin_1_target_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_denorm = np.array(y_test_denorm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 743.,  720.,  666., ...,  695.,  433., 1009.], dtype=float32)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_denorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin1 = {}\n",
    "\n",
    "bin1['Mean Absolute Error:'] =  mean_absolute_error(y_test_denorm, y_pred_denorm)  \n",
    "bin1['Mean Squared Error:'] =  mean_squared_error(y_test_denorm, y_pred_denorm) \n",
    "bin1['Root Mean Squared Error:'] = np.sqrt(mean_squared_error(y_test_denorm, y_pred_denorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean Absolute Error:': 71.65003,\n",
       " 'Mean Squared Error:': 7957.2256,\n",
       " 'Root Mean Squared Error:': 89.203285}"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bin_2 = train_data.loc[train_data['bin'] == 2]\n",
    "train_data_bin_2_input = train_data_bin_2[col]\n",
    "train_data_bin_2_target = train_data_bin_2['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bin_2_target_min = train_data_bin_2_target.min()\n",
    "train_data_bin_2_target_max = train_data_bin_2_target.max()\n",
    "\n",
    "# normalize y\n",
    "train_data_bin_2_target_norm = (train_data_bin_2_target - train_data_bin_2_target_min) / (train_data_bin_2_target_max - train_data_bin_2_target_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test,y_train,y_test = train_test_split(train_data_bin_2_input,train_data_bin_2_target_norm, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "92742      0.65907\n",
       "21896     0.020942\n",
       "32371     0.611026\n",
       "105110    0.527872\n",
       "95234     0.575608\n",
       "            ...   \n",
       "32583     0.239298\n",
       "129478    0.122267\n",
       "110440    0.915614\n",
       "2505      0.124731\n",
       "45744     0.959963\n",
       "Name: price, Length: 37432, dtype: object"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67062     0.583308\n",
       "22478     0.182938\n",
       "122992    0.580536\n",
       "22811     0.862027\n",
       "86320     0.392978\n",
       "            ...   \n",
       "133912    0.856483\n",
       "97834     0.596551\n",
       "84018     0.426548\n",
       "33105     0.495226\n",
       "37103     0.963351\n",
       "Name: price, Length: 9358, dtype: float32"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "293/293 [==============================] - 1s 2ms/step - loss: 0.0072 - val_loss: 8033171.5000\n",
      "Epoch 2/400\n",
      "293/293 [==============================] - 1s 2ms/step - loss: 0.0071 - val_loss: 8033204.0000\n",
      "Epoch 3/400\n",
      "293/293 [==============================] - 1s 2ms/step - loss: 0.0070 - val_loss: 8033318.5000\n",
      "Epoch 4/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0070 - val_loss: 8033251.5000\n",
      "Epoch 5/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 8033339.5000\n",
      "Epoch 6/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0070 - val_loss: 8033449.0000\n",
      "Epoch 7/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0069 - val_loss: 8033365.0000\n",
      "Epoch 8/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 8033256.5000\n",
      "Epoch 9/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 8033445.0000\n",
      "Epoch 10/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 8033388.0000\n",
      "Epoch 11/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 8033164.5000\n",
      "Epoch 12/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 8033261.0000\n",
      "Epoch 13/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 8033336.0000\n",
      "Epoch 14/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0067 - val_loss: 8033234.5000\n",
      "Epoch 15/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0068 - val_loss: 8033318.0000\n",
      "Epoch 16/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 8033255.5000\n",
      "Epoch 17/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 8033354.0000\n",
      "Epoch 18/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0066 - val_loss: 8033190.0000\n",
      "Epoch 19/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 8033446.5000\n",
      "Epoch 20/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 8033267.0000\n",
      "Epoch 21/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 8033143.0000\n",
      "Epoch 22/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 8033356.5000\n",
      "Epoch 23/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 8033306.5000\n",
      "Epoch 24/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 8033364.5000\n",
      "Epoch 25/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0065 - val_loss: 8033196.0000\n",
      "Epoch 26/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 8033266.0000\n",
      "Epoch 27/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 8033350.5000\n",
      "Epoch 28/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 8033285.5000\n",
      "Epoch 29/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 8033322.0000\n",
      "Epoch 30/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 8033268.0000\n",
      "Epoch 31/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 8033319.5000\n",
      "Epoch 32/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0064 - val_loss: 8033309.0000\n",
      "Epoch 33/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 8033246.0000\n",
      "Epoch 34/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 8033257.5000\n",
      "Epoch 35/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 8033316.0000\n",
      "Epoch 36/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0063 - val_loss: 8033232.0000\n",
      "Epoch 37/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 8033370.5000\n",
      "Epoch 38/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0063 - val_loss: 8033229.5000\n",
      "Epoch 39/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 8033317.0000\n",
      "Epoch 40/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 8033410.5000\n",
      "Epoch 41/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 8033385.5000\n",
      "Epoch 42/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 8033224.0000\n",
      "Epoch 43/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 8033334.5000\n",
      "Epoch 44/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 8033299.5000\n",
      "Epoch 45/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 8033261.0000\n",
      "Epoch 46/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 8033281.0000\n",
      "Epoch 47/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 8033309.0000\n",
      "Epoch 48/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 8033255.5000\n",
      "Epoch 49/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0061 - val_loss: 8033318.0000\n",
      "Epoch 50/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 8033451.0000\n",
      "Epoch 51/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 8033427.5000\n",
      "Epoch 52/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 8033325.0000\n",
      "Epoch 53/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 8033359.0000\n",
      "Epoch 54/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0060 - val_loss: 8033268.0000\n",
      "Epoch 55/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 8033400.0000\n",
      "Epoch 56/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 8033311.5000\n",
      "Epoch 57/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 8033255.5000\n",
      "Epoch 58/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0059 - val_loss: 8033231.0000\n",
      "Epoch 59/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 8033196.0000\n",
      "Epoch 60/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 8033229.5000\n",
      "Epoch 61/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0058 - val_loss: 8033286.5000\n",
      "Epoch 62/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 8033262.0000\n",
      "Epoch 63/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0057 - val_loss: 8033195.5000\n",
      "Epoch 64/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 8033216.5000\n",
      "Epoch 65/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 8033341.5000\n",
      "Epoch 66/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0057 - val_loss: 8033386.0000\n",
      "Epoch 67/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 8033371.5000\n",
      "Epoch 68/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 8033227.0000\n",
      "Epoch 69/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 8033262.5000\n",
      "Epoch 70/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 8033327.5000\n",
      "Epoch 71/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 8033342.5000\n",
      "Epoch 72/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 8033231.0000\n",
      "Epoch 73/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 8033299.5000\n",
      "Epoch 74/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 8033177.0000\n",
      "Epoch 75/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 8033271.5000\n",
      "Epoch 76/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 8033300.5000\n",
      "Epoch 77/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 8033202.5000\n",
      "Epoch 78/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 8033232.0000\n",
      "Epoch 79/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 8033304.5000\n",
      "Epoch 80/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 8033448.5000\n",
      "Epoch 81/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 8033254.0000\n",
      "Epoch 82/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 8033319.5000\n",
      "Epoch 83/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 8033260.0000\n",
      "Epoch 84/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 8033150.5000\n",
      "Epoch 85/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 8033362.5000\n",
      "Epoch 86/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 8033339.0000\n",
      "Epoch 87/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033311.0000\n",
      "Epoch 88/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033314.5000\n",
      "Epoch 89/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033221.5000\n",
      "Epoch 90/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033271.5000\n",
      "Epoch 91/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033288.0000\n",
      "Epoch 92/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0062 - val_loss: 8033220.0000\n",
      "Epoch 93/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0055 - val_loss: 8033237.5000\n",
      "Epoch 94/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 8033305.5000\n",
      "Epoch 95/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0054 - val_loss: 8033339.5000\n",
      "Epoch 96/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033284.5000\n",
      "Epoch 97/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033272.5000\n",
      "Epoch 98/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033194.5000\n",
      "Epoch 99/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033189.0000\n",
      "Epoch 100/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033335.5000\n",
      "Epoch 101/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033237.5000\n",
      "Epoch 102/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033264.5000\n",
      "Epoch 103/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033323.0000\n",
      "Epoch 104/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033338.0000\n",
      "Epoch 105/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033245.0000\n",
      "Epoch 106/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033244.5000\n",
      "Epoch 107/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033185.0000\n",
      "Epoch 108/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033260.0000\n",
      "Epoch 109/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033233.0000\n",
      "Epoch 110/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033290.0000\n",
      "Epoch 111/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033193.5000\n",
      "Epoch 112/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033315.0000\n",
      "Epoch 113/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033296.0000\n",
      "Epoch 114/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033252.0000\n",
      "Epoch 115/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033222.5000\n",
      "Epoch 116/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033400.0000\n",
      "Epoch 117/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033303.0000\n",
      "Epoch 118/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033280.0000\n",
      "Epoch 119/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033285.5000\n",
      "Epoch 120/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033199.0000\n",
      "Epoch 121/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033254.0000\n",
      "Epoch 122/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033325.5000\n",
      "Epoch 123/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033193.5000\n",
      "Epoch 124/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033167.5000\n",
      "Epoch 125/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033332.0000\n",
      "Epoch 126/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033273.0000\n",
      "Epoch 127/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033249.5000\n",
      "Epoch 128/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033309.0000\n",
      "Epoch 129/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033238.0000\n",
      "Epoch 130/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0053 - val_loss: 8033302.0000\n",
      "Epoch 131/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033390.5000\n",
      "Epoch 132/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033173.5000\n",
      "Epoch 133/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033250.5000\n",
      "Epoch 134/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033229.5000\n",
      "Epoch 135/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033340.5000\n",
      "Epoch 136/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033342.5000\n",
      "Epoch 137/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033355.5000\n",
      "Epoch 138/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033246.0000\n",
      "Epoch 139/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033126.0000\n",
      "Epoch 140/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033268.0000\n",
      "Epoch 141/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033287.0000\n",
      "Epoch 142/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033240.0000\n",
      "Epoch 143/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033185.5000\n",
      "Epoch 144/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0052 - val_loss: 8033313.5000\n",
      "Epoch 145/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033206.0000\n",
      "Epoch 146/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033181.5000\n",
      "Epoch 147/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033274.0000\n",
      "Epoch 148/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033304.0000\n",
      "Epoch 149/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033297.5000\n",
      "Epoch 150/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033278.5000\n",
      "Epoch 151/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033344.0000\n",
      "Epoch 152/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033369.5000\n",
      "Epoch 153/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033279.5000\n",
      "Epoch 154/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033351.0000\n",
      "Epoch 155/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033249.5000\n",
      "Epoch 156/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033371.5000\n",
      "Epoch 157/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033167.5000\n",
      "Epoch 158/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033320.5000\n",
      "Epoch 159/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033226.0000\n",
      "Epoch 160/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033286.5000\n",
      "Epoch 161/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033304.5000\n",
      "Epoch 162/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033178.0000\n",
      "Epoch 163/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033269.5000\n",
      "Epoch 164/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033141.0000\n",
      "Epoch 165/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033243.5000\n",
      "Epoch 166/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033231.0000\n",
      "Epoch 167/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033244.5000\n",
      "Epoch 168/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033265.5000\n",
      "Epoch 169/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033327.5000\n",
      "Epoch 170/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033230.5000\n",
      "Epoch 171/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033319.5000\n",
      "Epoch 172/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033212.0000\n",
      "Epoch 173/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033241.5000\n",
      "Epoch 174/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033196.0000\n",
      "Epoch 175/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033234.5000\n",
      "Epoch 176/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033282.0000\n",
      "Epoch 177/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033239.0000\n",
      "Epoch 178/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033322.0000\n",
      "Epoch 179/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033221.5000\n",
      "Epoch 180/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033326.5000\n",
      "Epoch 181/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033213.5000\n",
      "Epoch 182/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033346.0000\n",
      "Epoch 183/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033370.5000\n",
      "Epoch 184/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033268.0000\n",
      "Epoch 185/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033250.5000\n",
      "Epoch 186/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0051 - val_loss: 8033297.0000\n",
      "Epoch 187/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033314.5000\n",
      "Epoch 188/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033319.5000\n",
      "Epoch 189/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033297.5000\n",
      "Epoch 190/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033262.0000\n",
      "Epoch 191/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033291.5000\n",
      "Epoch 192/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033295.0000\n",
      "Epoch 193/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033316.0000\n",
      "Epoch 194/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033331.0000\n",
      "Epoch 195/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033304.5000\n",
      "Epoch 196/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033268.0000\n",
      "Epoch 197/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033309.0000\n",
      "Epoch 198/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033260.0000\n",
      "Epoch 199/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033373.0000\n",
      "Epoch 200/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 8033318.0000\n",
      "Epoch 201/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033220.5000\n",
      "Epoch 202/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033212.0000\n",
      "Epoch 203/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033326.5000\n",
      "Epoch 204/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033206.5000\n",
      "Epoch 205/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033191.0000\n",
      "Epoch 206/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033293.5000\n",
      "Epoch 207/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033307.5000\n",
      "Epoch 208/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033224.0000\n",
      "Epoch 209/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033180.5000\n",
      "Epoch 210/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033311.0000\n",
      "Epoch 211/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033192.5000\n",
      "Epoch 212/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033297.0000\n",
      "Epoch 213/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033244.5000\n",
      "Epoch 214/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033321.5000\n",
      "Epoch 215/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033304.0000\n",
      "Epoch 216/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033359.0000\n",
      "Epoch 217/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033272.5000\n",
      "Epoch 218/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033344.0000\n",
      "Epoch 219/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033255.5000\n",
      "Epoch 220/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033376.5000\n",
      "Epoch 221/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033297.5000\n",
      "Epoch 222/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0050 - val_loss: 8033261.0000\n",
      "Epoch 223/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033269.5000\n",
      "Epoch 224/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033214.5000\n",
      "Epoch 225/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033186.5000\n",
      "Epoch 226/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033225.0000\n",
      "Epoch 227/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033275.0000\n",
      "Epoch 228/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033282.0000\n",
      "Epoch 229/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033283.0000\n",
      "Epoch 230/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033271.5000\n",
      "Epoch 231/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033268.0000\n",
      "Epoch 232/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033211.0000\n",
      "Epoch 233/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033225.0000\n",
      "Epoch 234/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033283.0000\n",
      "Epoch 235/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033299.5000\n",
      "Epoch 236/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033232.0000\n",
      "Epoch 237/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033344.0000\n",
      "Epoch 238/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033230.5000\n",
      "Epoch 239/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033247.0000\n",
      "Epoch 240/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033288.0000\n",
      "Epoch 241/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033227.0000\n",
      "Epoch 242/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033233.0000\n",
      "Epoch 243/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033268.0000\n",
      "Epoch 244/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033233.0000\n",
      "Epoch 245/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033262.0000\n",
      "Epoch 246/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 8033293.5000\n",
      "Epoch 247/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033263.5000\n",
      "Epoch 248/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033241.5000\n",
      "Epoch 249/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033280.0000\n",
      "Epoch 250/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033269.0000\n",
      "Epoch 251/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033236.5000\n",
      "Epoch 252/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033339.0000\n",
      "Epoch 253/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033310.0000\n",
      "Epoch 254/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033205.0000\n",
      "Epoch 255/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033289.0000\n",
      "Epoch 256/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033254.0000\n",
      "Epoch 257/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033244.5000\n",
      "Epoch 258/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033311.0000\n",
      "Epoch 259/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033234.5000\n",
      "Epoch 260/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033297.0000\n",
      "Epoch 261/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033331.0000\n",
      "Epoch 262/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033357.5000\n",
      "Epoch 263/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033288.0000\n",
      "Epoch 264/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033215.5000\n",
      "Epoch 265/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033344.0000\n",
      "Epoch 266/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033213.0000\n",
      "Epoch 267/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033159.5000\n",
      "Epoch 268/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033307.5000\n",
      "Epoch 269/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033280.0000\n",
      "Epoch 270/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033301.0000\n",
      "Epoch 271/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033290.0000\n",
      "Epoch 272/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 8033254.0000\n",
      "Epoch 273/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033317.0000\n",
      "Epoch 274/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033304.5000\n",
      "Epoch 275/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033194.5000\n",
      "Epoch 276/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033204.0000\n",
      "Epoch 277/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033309.0000\n",
      "Epoch 278/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033283.5000\n",
      "Epoch 279/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033318.0000\n",
      "Epoch 280/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033332.0000\n",
      "Epoch 281/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033276.0000\n",
      "Epoch 282/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033210.0000\n",
      "Epoch 283/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033197.0000\n",
      "Epoch 284/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033277.5000\n",
      "Epoch 285/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033287.0000\n",
      "Epoch 286/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033218.0000\n",
      "Epoch 287/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033250.5000\n",
      "Epoch 288/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033293.5000\n",
      "Epoch 289/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033280.0000\n",
      "Epoch 290/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033302.0000\n",
      "Epoch 291/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033288.0000\n",
      "Epoch 292/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033239.0000\n",
      "Epoch 293/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033277.5000\n",
      "Epoch 294/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033244.5000\n",
      "Epoch 295/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033339.5000\n",
      "Epoch 296/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033307.5000\n",
      "Epoch 297/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033369.5000\n",
      "Epoch 298/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033208.5000\n",
      "Epoch 299/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033345.0000\n",
      "Epoch 300/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033218.0000\n",
      "Epoch 301/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033254.0000\n",
      "Epoch 302/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033318.0000\n",
      "Epoch 303/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033227.0000\n",
      "Epoch 304/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033273.0000\n",
      "Epoch 305/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033354.0000\n",
      "Epoch 306/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033299.5000\n",
      "Epoch 307/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033298.5000\n",
      "Epoch 308/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033237.5000\n",
      "Epoch 309/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033232.0000\n",
      "Epoch 310/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033289.0000\n",
      "Epoch 311/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033311.5000\n",
      "Epoch 312/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033274.0000\n",
      "Epoch 313/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0056 - val_loss: 8033316.0000\n",
      "Epoch 314/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033242.5000\n",
      "Epoch 315/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033206.5000\n",
      "Epoch 316/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033290.5000\n",
      "Epoch 317/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033272.5000\n",
      "Epoch 318/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0049 - val_loss: 8033325.0000\n",
      "Epoch 319/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033291.5000\n",
      "Epoch 320/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033268.0000\n",
      "Epoch 321/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033273.0000\n",
      "Epoch 322/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033304.5000\n",
      "Epoch 323/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033269.5000\n",
      "Epoch 324/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033310.0000\n",
      "Epoch 325/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033260.0000\n",
      "Epoch 326/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033185.5000\n",
      "Epoch 327/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033240.0000\n",
      "Epoch 328/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033269.0000\n",
      "Epoch 329/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033199.0000\n",
      "Epoch 330/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033264.5000\n",
      "Epoch 331/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033234.0000\n",
      "Epoch 332/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033249.5000\n",
      "Epoch 333/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033258.5000\n",
      "Epoch 334/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033300.5000\n",
      "Epoch 335/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033295.0000\n",
      "Epoch 336/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033262.0000\n",
      "Epoch 337/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033275.0000\n",
      "Epoch 338/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 8033214.5000\n",
      "Epoch 339/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033291.5000\n",
      "Epoch 340/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033303.0000\n",
      "Epoch 341/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033290.0000\n",
      "Epoch 342/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033225.0000\n",
      "Epoch 343/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033210.0000\n",
      "Epoch 344/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033253.0000\n",
      "Epoch 345/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033316.0000\n",
      "Epoch 346/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033246.0000\n",
      "Epoch 347/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033281.0000\n",
      "Epoch 348/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033239.0000\n",
      "Epoch 349/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033273.0000\n",
      "Epoch 350/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033212.0000\n",
      "Epoch 351/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033354.5000\n",
      "Epoch 352/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033208.5000\n",
      "Epoch 353/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033276.5000\n",
      "Epoch 354/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 8033268.0000\n",
      "Epoch 355/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033226.0000\n",
      "Epoch 356/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033178.0000\n",
      "Epoch 357/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033297.5000\n",
      "Epoch 358/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033177.0000\n",
      "Epoch 359/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033197.0000\n",
      "Epoch 360/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033276.5000\n",
      "Epoch 361/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033312.5000\n",
      "Epoch 362/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033285.5000\n",
      "Epoch 363/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033285.5000\n",
      "Epoch 364/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033230.5000\n",
      "Epoch 365/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033256.5000\n",
      "Epoch 366/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033260.0000\n",
      "Epoch 367/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033343.0000\n",
      "Epoch 368/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033257.5000\n",
      "Epoch 369/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033217.0000\n",
      "Epoch 370/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033316.0000\n",
      "Epoch 371/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033312.5000\n",
      "Epoch 372/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 8033298.5000\n",
      "Epoch 373/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 8033200.5000\n",
      "Epoch 374/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033333.5000\n",
      "Epoch 375/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033293.5000\n",
      "Epoch 376/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033244.5000\n",
      "Epoch 377/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033311.5000\n",
      "Epoch 378/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 8033320.5000\n",
      "Epoch 379/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033287.0000\n",
      "Epoch 380/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033308.0000\n",
      "Epoch 381/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 8033312.5000\n",
      "Epoch 382/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033286.5000\n",
      "Epoch 383/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033227.0000\n",
      "Epoch 384/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033245.0000\n",
      "Epoch 385/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033233.0000\n",
      "Epoch 386/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033234.0000\n",
      "Epoch 387/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033191.0000\n",
      "Epoch 388/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033241.0000\n",
      "Epoch 389/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 8033302.0000\n",
      "Epoch 390/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033303.0000\n",
      "Epoch 391/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033188.5000\n",
      "Epoch 392/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033271.5000\n",
      "Epoch 393/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033263.5000\n",
      "Epoch 394/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033243.5000\n",
      "Epoch 395/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0048 - val_loss: 8033297.5000\n",
      "Epoch 396/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033360.0000\n",
      "Epoch 397/400\n",
      "293/293 [==============================] - 0s 2ms/step - loss: 0.0047 - val_loss: 8033294.0000\n",
      "Epoch 398/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0048 - val_loss: 8033242.5000\n",
      "Epoch 399/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033258.5000\n",
      "Epoch 400/400\n",
      "293/293 [==============================] - 0s 1ms/step - loss: 0.0047 - val_loss: 8033212.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c1bef7ca60>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train.values,\n",
    "          validation_data=(X_test,y_test.values),\n",
    "          batch_size=128,epochs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_denorm = y_pred * (train_data_bin_2_target_max - train_data_bin_2_target_min) + (train_data_bin_2_target_min)\n",
    "y_test_denorm = y_test * (train_data_bin_2_target_max - train_data_bin_2_target_min) + (train_data_bin_2_target_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt konsa region mai error aaraha hai\n",
    "#mehenge wale cheez ko galar "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin2 = {}\n",
    "\n",
    "bin2['Mean Absolute Error:'] =  mean_absolute_error(y_test_denorm, y_pred_denorm)  \n",
    "bin2['Mean Squared Error:'] =  mean_squared_error(y_test_denorm, y_pred_denorm) \n",
    "bin2['Root Mean Squared Error:'] = np.sqrt(mean_squared_error(y_test_denorm, y_pred_denorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean Absolute Error:': 168.66667,\n",
       " 'Mean Squared Error:': 54968.055,\n",
       " 'Root Mean Squared Error:': 234.45267}"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bin_3 = train_data.loc[train_data['bin'] == 3]\n",
    "train_data_bin_3_input = train_data_bin_3[col]\n",
    "train_data_bin_3_target = train_data_bin_3['price']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_bin_3_target_min = train_data_bin_3_target.min()\n",
    "train_data_bin_3_target_max = train_data_bin_3_target.max()\n",
    "\n",
    "# normalize y\n",
    "train_data_bin_3_target_norm = (train_data_bin_3_target - train_data_bin_3_target_min) / (train_data_bin_3_target_max - train_data_bin_3_target_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train ,X_test,y_train,y_test = train_test_split(train_data_bin_3_input,train_data_bin_3_target_norm, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.astype('float32')\n",
    "y_train = y_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "y_test = y_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "270/270 [==============================] - 1s 2ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 2/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 3/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 4/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 5/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 6/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 7/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 8/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 9/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 10/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 11/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 12/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 13/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 14/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 15/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 16/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 17/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 18/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 19/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 20/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 21/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 22/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 23/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 24/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 25/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 26/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 27/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 28/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 29/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 30/50\n",
      "270/270 [==============================] - 0s 2ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 31/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 32/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 33/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 34/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 35/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 36/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 37/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 38/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 39/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 40/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 41/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 42/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 43/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 44/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 45/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 46/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 47/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 48/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 49/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n",
      "Epoch 50/50\n",
      "270/270 [==============================] - 0s 1ms/step - loss: 0.1603 - val_loss: 0.1599\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2c1bf7a1f40>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train.values,\n",
    "          validation_data=(X_test,y_test.values),\n",
    "          batch_size=128,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270/270 [==============================] - 0s 1ms/step\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_denorm = y_pred * (train_data_bin_2_target_max - train_data_bin_2_target_min) + (train_data_bin_2_target_min)\n",
    "y_test_denorm = y_test * (train_data_bin_2_target_max - train_data_bin_2_target_min) + (train_data_bin_2_target_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin3 = {}\n",
    "\n",
    "bin3['Mean Absolute Error:'] =  mean_absolute_error(y_test_denorm, y_pred_denorm)  \n",
    "bin3['Mean Squared Error:'] =  mean_squared_error(y_test_denorm, y_pred_denorm) \n",
    "bin3['Root Mean Squared Error:'] = np.sqrt(mean_squared_error(y_test_denorm, y_pred_denorm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Mean Absolute Error:': 967.8303,\n",
       " 'Mean Squared Error:': 1686172.4,\n",
       " 'Root Mean Squared Error:': 1298.527}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
